ð•¶ð–”ð–—ð–‡ð–Žð–™ð–ˆð–
# PrzykÅ‚ady uÅ¼ycia
## Sprawdzanie parzystoÅ›ci
### Dane wejÅ›ciowe
$\vec{u}$ - $n$-elementowy wektor skÅ‚adajÄ…cy siÄ™ z 0 i 1
### Dane wyjÅ›ciowe
$1$, jeÅ›li liczba jedynek jest nieparzysta,\
$0$ w przeciwnym przypadku
### Struktura sieci
Dwuwarstwowa sieÄ‡ jednokierunkowa z $n$ wejÅ›Ä‡ i jednym wyjÅ›ciu
### ZbiÃ³r danych uczÄ…cych
Udowodniono, Å¼e dla wektora o rozmiarze $n$ skÅ‚adajÄ…cego siÄ™ z $0$ i $1$ wystarczy zbiÃ³r danych
uczÄ…cych o wielkoÅ›ci $2^n$.

$
{u,z} = \begin{bmatrix}
1 & 0 &0&0&|1\\
1&1&0&0&|0\\
0&1&1&1&|1\\
\vdots&\vdots&\vdots&\vdots&\vdots
\end{bmatrix}
$

## Kompresja
Zadanie kompresji danych polega na zmniejszeniu iloÅ›ci informacji przechowywanych lub
transmitowanych przy zachowaniu moÅ¼liwoÅ›ci jej peÅ‚nego odtworzenia (dekompresji). Mamy kompresjÄ™
stratnÄ… i bez stratnÄ…. PrzykÅ‚adem kompresji bez stratnej moÅ¼e byÄ‡ drzewo Huffmana
### Dane wejÅ›ciowe
$n$-elementowy wektor $\vec{u}$
### Dane wyjÅ›ciowe
$n$-elementowy wektor $\vec{y}$
### Struktura sieci
TrÃ³jwarstwowa sieÄ‡ jednokierunkowa

$i=1,2,...,n$ - Indeksy wejÅ›ciowe\
$j=1,2,...,n$ - Indeksy wyjÅ›ciowe\
$k=1,2,...,q; q \leq n$ - Indeksy warstwy ukrytej

### Zestaw uczÄ…cy
$\{\vec{u}^\mu,\vec{u}^\mu\}, \mu=1,2...P$

Na etapie uczenia metodÄ… propagacji wstecznej wyznaczane sÄ… wartoÅ›ci wag $w_{ik}$ oraz ${v_kj}$ Å¼e
sieÄ‡ taka po nauczeniu moÅ¼e byÄ‡ rozdzielona na dwie czÄ™Å›ci, lewa to kompresor, a prawa to
dekompresor. Tak zrealizowana kompresja danych jest kompresjÄ… stratnÄ…, gdyÅ¼ algorytm uczenia
(propagacja wsteczna) nie daje moÅ¼liwoÅ›ci zakoÅ„czenia procesu uczenia w skoÅ„czonym czasie z
bÅ‚Ä™dem zerowym.

## Zastosowanie sieci neuronowej do wyznaczenia macierzy odwrotnej
ZaÅ‚Ã³Å¼my, Å¼e jest dana macierz kwadratowa $A$ rzÄ™du $n$ ($dim A=(n\times n)$). NaleÅ¼y zaprojektowaÄ‡
sieÄ‡ neuronowÄ… obliczajÄ…cÄ… macierz odwrotnÄ… $B = A^{-1}$.\
$B*A=I$

ZaÅ‚Ã³Å¼my, Å¼e mamy wektor $\vec{x}=[x_1, x_2, ..., x_n]$

$B*A=I/*x$

$BAx=x \Rightarrow BAx-x=0$

$E=\frac{1}{2} ||BAx-x||^2_2$

$||x||_2 = \sqrt{\displaystyle\sum_{i=1}^nx_i^2}$

ZauwaÅ¼my, Å¼e wektor $\vec{x}$ peÅ‚ni podwÃ³jnÄ… rolÄ™. Jest wektorem uczÄ…cym, czyli wejÅ›ciem do
sieci. PeÅ‚ni teÅ¼ rolÄ™ wektora zadanego.

### Zestaw uczÄ…cy
$\{x^\mu,x^\mu\}, \mu=1,2...P$

# JakieÅ› zadanie
$f_0$ - stan normalny\
$f_1$ - pÄ™kniÄ™cie\
$f_2$ - uszkodzenie pompy\
$f_3$ - zarastanie

SygnaÅ‚y wejÅ›ciowe:
${P,T,Q}$

WyjÅ›cia:
$f_0,f_1,f_2,f_3$ o wartoÅ›ci $0$ lub $1$\
$1$ - poprawne\
$0$ - niepoprawne

```
graph LR;
P-->net["SieÄ‡ neuronowa"]
T-->net
Q-->net
net-->f_0
net-->f_1
net-->f_2
net-->f_3
```
## Struktura sieci
3 warstwowa
## Zestaw uczÄ…cy
$
f_0= \begin{Bmatrix}
100& 70& 200 &|1\\
95& 78& 250 &|1\\
\vdots &&&|1\\
93& 71& 210 &|1
\end{Bmatrix}
$

$
f_1=\begin{Bmatrix}
70&40&300&|1 \\
20&45&200&|1\\
\cdots&&&|1
\end{Bmatrix}
$

$f_3=\begin{Bmatrix}
\cdots
\end{Bmatrix}
$

$f_4=\begin{Bmatrix}
\cdots
\end{Bmatrix}
$

# Logika rozmyta i zastosowania
| logika klasyczna                 | logika rozmyta         |
| -                                | -                      |
| CoÅ› albo jest w zbiorze albo nie | MoÅ¼e naleÅ¼eÄ‡ czÄ™Å›ciowo |

## Zastosowanie logiki rozmytej w diagnostyce obiektÃ³w technicznych

```
graph LR;
u-->obiekt
u-->model
obiekt-->|y|o(( ))
model-->|y_u|o
o-->w[r=y-y_u]
```
$r$- sygnaÅ‚ residuum

$r = \begin{cases}
1 \text{ - gdy nie przekroczony} \\
0 \text{ - gdy przekroczony}
\end{cases}$

### Rozmyta ocena wartoÅ›ci residuum
KaÅ¼demu residuum $N$ przyporzÄ…dkowaÄ‡ moÅ¼na zmiennÄ… opisujÄ…cÄ… wyniki testu. W najgorszym przypadku
zbiÃ³r posiada 2 wyniki, pozytywny i negatywny. 

### ReguÅ‚y wnioskowania rozmytego
$R_0$ JeÅ¼eli $S_1=P$ i $S_j=P$ to wszystko jest OK\
$R_k$ JeÅ¼eli $S_1 = N$ i $S_j = P$ to np. Uszkodzenie $f_k$

### Rozmyte wnioskowanie
Analiza zestawu reguÅ‚

#### Rozmyta struktura diagnostyki
```
graph LR;
residuum==>rozm[Blok rozmywania]
rozm==>wn[Blok wnioskowania]
wn==>diagnoza
```
$\{f_1, 0.8\}$ lub $\{f_3, 0.3\}$\
$\{f_0, 1\}$

## Struktura ukÅ‚adu sterowania rozmytego

```
graph LR;
a>"SygnaÅ‚ rzeczywisty"]==>rozm[Blok rozmywania]
rozm==>bp[Blok przetwarzania]
bp==>bw[Blok wyostrzania]
bw==>s>Sterowanie]
```
